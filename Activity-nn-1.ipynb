{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Nearest Neighbors using LSH\n",
    "\n",
    "This notebook will show the give and take between building multiple hash tables and employing multiple hash functions when searching for approximate neighbors using LSH. The demonstration is meant to clarify slide 12 from slide deck 3, on Nearest Neighbors.\n",
    "\n",
    "I have written a basic LSH implementation in Python, with instantiations for the cosine similarity, Hamming distance, and the Jaccard coefficient LSH families. The code is written in OOP style and can be easily extended to other LSH families. Take a look at lsh.py for the details. In this demo, we will be using the cosine similarity version of the LSH data structure, *clsh*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import numpy as np\n",
    "from lsh import clsh, jlsh, generateSamples, findNeighborsBrute, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will generate some random samples, and split the data into train (X) and test (Y) subsets. Samples are generated from 100 gausian blobs, i.e., points will be fairly spread out as far as their cosine similarity is concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 100) (100, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-21.93495444, -70.72167468,  33.48179766, ...,  -6.17863717,\n",
       "          9.90087979,  35.9082757 ],\n",
       "       [ 61.27248139,  23.79628551,  40.03762585, ...,  24.85593323,\n",
       "          7.92610523, -70.17862846],\n",
       "       [ -5.85781226,  34.64220695, 102.62236436, ..., -42.18277623,\n",
       "        -39.91321344,  14.03259274],\n",
       "       ...,\n",
       "       [  8.86107962,  42.08387881,  26.05809411, ...,  25.25709338,\n",
       "         29.36297867, -33.06144215],\n",
       "       [  8.44786088,  28.41639451,  -8.4230125 , ...,   7.16146463,\n",
       "         16.04942015, 118.24049129],\n",
       "       [ 47.79726309, -23.72759299, -65.28597747, ..., -73.54256933,\n",
       "         30.28209599, -45.35842083]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generateSamples(nsamples=1000, nfeatures=100, nclusters=64, clusterstd=50, binary=False)\n",
    "print(X.shape, Y.shape)\n",
    "X #added by hb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic concept in LSH is that of *hashing* the vectors using a random LSH family of hash functions. As we discussed in class, the LSH families will be more likely to assign the same hash value to similar items. This, however, does not happen all the time. First, let's see what the result of hashing a vector looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "L11 = clsh(X, ntables=1, nfunctions=1)\n",
    "for i in range(10):\n",
    "    print(L11.hash(X[i,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in slide 18, the output of the cosine family of LSH function is binary, depending on the sign of the dot-product $\\langle r,x\\rangle$ between the random unit vector $r$ and our input vector $x=X[i,:]$.\n",
    "\n",
    "Note that we created a single table in our LSH data structure and are using a single LSH function to hash vectors. This means that we're simply partitioning vectors into two buckets. Some vectors will go to the bucket with ID 0, and others will go to the bucket with ID 1.\n",
    "\n",
    "When we instantiated the LSH data structure *L*, all the vectors in X were already assigned to their respective buckets. Let's see how many vectors each bucket has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket ID 0 has 445 vectors.\n",
      "Bucket ID 1 has 455 vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Bucket ID 0 has %d vectors.\" % len(L11.tables[0]['0']))\n",
    "print(\"Bucket ID 1 has %d vectors.\" % len(L11.tables[0]['1']))\n",
    "#'X' had a size of [900,100] meaning 900 rows with 100 columns\n",
    "# which has divided into two buckets '0' and '1'\n",
    "# bucket '0' has 446 vectors and '1' has 454 of the total of 900 rows in 'X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when it's time to find neighbors for a new vector, say $y=Y[0,:]$, the first vector in our test set, we hash the vector to see which bucket we should look in to find neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(L11.hash(Y[0,:], tid=0, fid=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I passed in the ID of the table I'm searching in and the ID of the function I'm hashing with. For LSH to work, we have to use the same hashing functions that were used to create the table(s). Therefore, $clsh$ stores the randomly generated functions it created for each table.\n",
    "\n",
    "Now, it looks like I have to compare $y$ against almost half of the vectors in $X$, which is a lot, and leads to low *precision*. Precision is the fraction of retrieved instances (the vectors we compared against) that are relevant (that would also be in the exact result). Since the number of objects we're comparing against is high, precision will be low. In order to increase the precision, I can use several hash functions and concatenate their results. Increasing the precision will also reduc the amount of time spent finding neighbors, as we will have fewer objects to compare against.\n",
    "\n",
    "Let's say I use 2 hash functions from the Cosine LSH family. Then, the possible resulting hash values would be 00, 01, 10, and 11, spliting the vectors in X into 4 buckets (instead of 2, when we used 1 function). If we use 3 functions, we get 8 buckets. In general, using $f$ functions will split the \"search space\" into $2^f$ buckets.\n",
    "\n",
    "Let's try this using 3 functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket ID 111 has 105 vectors.\n",
      "Bucket ID 011 has 123 vectors.\n",
      "Bucket ID 100 has 119 vectors.\n",
      "Bucket ID 001 has 86 vectors.\n",
      "Bucket ID 010 has 132 vectors.\n",
      "Bucket ID 110 has 107 vectors.\n",
      "Bucket ID 000 has 104 vectors.\n",
      "Bucket ID 101 has 124 vectors.\n",
      "\n",
      "We only need to compare y against vectors in bucket 110.\n"
     ]
    }
   ],
   "source": [
    "# using 3 functions. \n",
    "\n",
    "L13 = clsh(X, ntables=1, nfunctions=3)\n",
    "for k in L13.tables[0].keys():\n",
    "    print(\"Bucket ID %s has %d vectors.\" % (k, len(L13.tables[0][k])))\n",
    "    \n",
    "print(\"\\nWe only need to compare y against vectors in bucket %s.\" % L13.signature(Y[0,:], tid=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note**: Note that in this academic LSH implementation we use a simple way to generate bucket IDs. We concatenate the string representation of the resulting hash value from each hash function. LSH libraries often implement a secondary (exact) hash function for generating numeric IDs for the buckets. A similar scheme is proposed in the LSH reference I nored on Canvas: [SPM'08] Malcolm Slaney and Michael Casey. Locality-Sensitive Hashing for Finding Nearest Neighbors. Lecture Notes. IEEE Signal Processing Magazine, 2008.\n",
    "\n",
    "It is easy to see we now have much fewer vectors to compare against when we search for $y$'s neighbors. However, some of the true neighbors may have been accidentally placed in other buckets, which lowers *recall*. Recall (also known in Statistics references as *sensitivity*) is the fraction of relevant instances that are retrieved, i.e., the fraction of true neighbors in our top-$k$ divided by $k$. \n",
    "\n",
    "Let's compare the mean recall for finding neighbors using 1 hash function vs. 3 hash functions. To do that, we will first have to find the \"true neighbors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of computed similarities for the brute-force approach: 90000.\n",
      "Recall with 1 hash function: 0.557900. Number of computed similarities: 44980.\n",
      "Recall with 3 hash functions: 0.169900. Number of computed similarities: 11395.\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 100  # number of neighbors to find\n",
    "nbrsExact = findNeighborsBrute(X, Y, k=k, sim=\"cos\")\n",
    "print(\"Number of computed similarities for the brute-force approach: %d.\" % (X.shape[0] * Y.shape[0]))\n",
    "nbrsTest11  = L11.findNeighbors(Y, k=k)\n",
    "nbrsTest13  = L13.findNeighbors(Y, k=k)\n",
    "print(\"Recall with 1 hash function: %f. Number of computed similarities: %d.\" % (recall(nbrsTest11, nbrsExact), L11.nsims))\n",
    "print(\"Recall with 3 hash functions: %f. Number of computed similarities: %d.\" % (recall(nbrsTest13, nbrsExact), L13.nsims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase the recall by building several LSH tables instead of one. Then, instead of looking in one bucket for $y$'s neighbors, we will be looking in one bucket in each table. The search method gets the set union of object IDs in all these buckets, and then computes similarities against all of them.\n",
    "\n",
    "### Excercise 1\n",
    "\n",
    "Compare the mean recall for finding neighbors using 1 table vs. 3 tables, when each table uses 3 hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using 3 functions in 3 tables each. \n",
    "\n",
    "L33 = clsh(X, ntables=3, nfunctions=3)\n",
    "\n",
    "#for i in range(0,3):\n",
    "#    print (\"Table no.\"+str(i))\n",
    "#    for k in L33.tables[i].keys():\n",
    "#        print(\"Bucket ID %s has %d vectors.\" % (k, len(L33.tables[i][k])))\n",
    "        \n",
    "#print(\"\\nWe only need to compare y against vectors in bucket %s.\" % L13.signature(Y[0,:], tid=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of computed similarities for the brute-force approach: 90000.\n",
      "Recall with 1 hash function: 0.169900. Number of computed similarities: 11395.\n",
      "Recall with 3 hash functions: 0.423000. Number of computed similarities: 29782.\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 100  # number of neighbors to find\n",
    "nbrsExact = findNeighborsBrute(X, Y, k=k, sim=\"cos\")\n",
    "print(\"Number of computed similarities for the brute-force approach: %d.\" % (X.shape[0] * Y.shape[0]))\n",
    "nbrsTest13  = L13.findNeighbors(Y, k=k)\n",
    "nbrsTest33  = L33.findNeighbors(Y, k=k)\n",
    "print(\"Recall with 1 hash function: %f. Number of computed similarities: %d.\" % (recall(nbrsTest13, nbrsExact), L13.nsims))\n",
    "print(\"Recall with 3 hash functions: %f. Number of computed similarities: %d.\" % (recall(nbrsTest33, nbrsExact), L33.nsims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given high enough # tables and # hashes (hash functions), we can achieve high recall and precision, sometimes at the expense of efficiency.\n",
    "\n",
    "### Excercise 2\n",
    "\n",
    "Find the minimum number of tables necessary to obtain `recall` of at least `0.90` using 3 functions. What is the number of computed similarities for that LSH forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 3 functions in 'n' tables each to get >=0.90 recall value\n",
    "\n",
    "L133 = clsh(X, ntables=13, nfunctions=3)\n",
    "\n",
    "# for i in range(0,6):\n",
    "#     print (\"Table no.\"+str(i))\n",
    "#     for k in L33.tables[i].keys():\n",
    "#         print(\"Bucket ID %s has %d vectors.\" % (k, len(L33.tables[i][k])))\n",
    "#         \n",
    "#print(\"\\nWe only need to compare y against vectors in bucket %s.\" % L13.signature(Y[0,:], tid=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of computed similarities for the brute-force approach: 90000.\n",
      "Recall with 3 hash function, 3 TABLES: 0.169900. Number of computed similarities: 11395.\n",
      "Recall with 3 hash functions, 13 TABLES: 0.910000. Number of computed similarities: 73534.\n",
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 100  # number of neighbors to find\n",
    "nbrsExact = findNeighborsBrute(X, Y, k=k, sim=\"cos\")\n",
    "print(\"Number of computed similarities for the brute-force approach: %d.\" % (X.shape[0] * Y.shape[0]))\n",
    "nbrsTest13  = L13.findNeighbors(Y, k=k)\n",
    "nbrsTest133  = L133.findNeighbors(Y, k=k)\n",
    "print(\"Recall with 3 hash function, 3 TABLES: %f. Number of computed similarities: %d.\" % (recall(nbrsTest13, nbrsExact), L13.nsims))\n",
    "print(\"Recall with 3 hash functions, 13 TABLES: %f. Number of computed similarities: %d.\" % (recall(nbrsTest133, nbrsExact), L133.nsims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer is 13 tables are required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Repeat Exrcise 1 and 2 using `Jaccard Coefficient` instead of `cosine similarity`. Note that you will need to re-generate samples using the `binary=True` parameter and re-compute `nbrsExact` for the new similarity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 100) (100, 100)\n"
     ]
    }
   ],
   "source": [
    "#put binary=true\n",
    "X, Y = generateSamples(nsamples=1000, nfeatures=100, nclusters=64, clusterstd=50, binary=True)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Compare the mean recall for finding neighbors using 1 table vs. 3 tables, when each table uses 3 hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of computed similarities for the brute-force approach: 90000.\n",
      "Recall with 1 hash function: 0.076200. Number of computed similarities: 3729.\n",
      "Recall with 3 hash functions: 0.226000. Number of computed similarities: 10771.\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using 3 functions in 3 tables each. \n",
    "Ljacc13 = jlsh(X, ntables=1, nfunctions=3)\n",
    "\n",
    "# using 3 functions in 3 tables each. \n",
    "Ljacc33 = jlsh(X, ntables=3, nfunctions=3)\n",
    "\n",
    "#finding recall\n",
    "nbrsExact = findNeighborsBrute(X, Y, k=k, sim=\"jac\") #options are cos, ham, jac\n",
    "print(\"Number of computed similarities for the brute-force approach: %d.\" % (X.shape[0] * Y.shape[0]))\n",
    "nbrsTest13  = Ljacc13.findNeighbors(Y, k=k)\n",
    "nbrsTest33  = Ljacc33.findNeighbors(Y, k=k)\n",
    "print(\"Recall with 1 hash function: %f. Number of computed similarities: %d.\" % (recall(nbrsTest13, nbrsExact), Ljacc13.nsims))\n",
    "print(\"Recall with 3 hash functions: %f. Number of computed similarities: %d.\" % (recall(nbrsTest33, nbrsExact), Ljacc33.nsims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the minimum number of tables necessary to obtain recall of at least 0.90 using 3 functions. What is the number of computed similarities for that LSH forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of computed similarities for the brute-force approach: 90000.\n",
      "Recall with 3 hash functions, x TABLES: 0.902400. Number of computed similarities: 60636.\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using 3 functions in 3 tables each. \n",
    "Ljacc33 = jlsh(X, ntables=31, nfunctions=3)\n",
    "\n",
    "#finding recall\n",
    "nbrsExact = findNeighborsBrute(X, Y, k=k, sim=\"jac\") #options are cos, ham, jac\n",
    "print(\"Number of computed similarities for the brute-force approach: %d.\" % (X.shape[0] * Y.shape[0]))\n",
    "\n",
    "nbrsTest33  = Ljacc33.findNeighbors(Y, k=k)\n",
    "\n",
    "print(\"Recall with 3 hash functions, x TABLES: %f. Number of computed similarities: %d.\" % (recall(nbrsTest33, nbrsExact), Ljacc33.nsims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: it took 31 Tables with Jaccard similarity to get a recall value of 0.90 . No. of computer similarities: 60781"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
